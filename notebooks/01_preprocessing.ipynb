{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc32e76d-6794-4ad2-a9e7-4c409a121337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory (should be data):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/blshen/ml-costs-thesis/data'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from pandas.tseries.offsets import MonthEnd\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options for better readability\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Access data directory\n",
    "os.chdir(\"../data\")\n",
    "print(\"Current directory (should be data):\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e1c6c59-b817-47b7-a12f-fda7648ffa2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Loaded 1,650 linking records\n",
      "   Unique GVKEYs: 1,264\n",
      "   Unique PERMNOs: 1,274\n"
     ]
    }
   ],
   "source": [
    "# LOAD LINK TABLE\n",
    "\n",
    "linker = pd.read_csv('linker.csv')\n",
    "\n",
    "# Fix dates\n",
    "linker['LINKDT'] = pd.to_datetime(linker['LINKDT'], errors='coerce')\n",
    "linker['LINKENDDT'] = linker['LINKENDDT'].replace(['E', 'e'], pd.NaT)\n",
    "linker['LINKENDDT'] = pd.to_datetime(linker['LINKENDDT'], errors='coerce')\n",
    "linker['LINKENDDT'] = linker['LINKENDDT'].fillna(pd.Timestamp('2024-12-31'))\n",
    "\n",
    "# Validation Checks\n",
    "print(f\"   Loaded {len(linker):,} linking records\")\n",
    "print(f\"   Unique GVKEYs: {linker['GVKEY'].nunique():,}\")\n",
    "print(f\"   Unique PERMNOs: {linker['LPERMNO'].nunique():,}\")\n",
    "\n",
    "# Rename for consistency\n",
    "linker = linker.rename(columns={\n",
    "    'GVKEY': 'gvkey',\n",
    "    'LPERMNO': 'PERMNO'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c9350a9-0831-40b6-8879-79fe95afd603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   109,015 quarterly observations\n",
      "   27,125 annual observations\n",
      "\n",
      "---\n",
      "\n",
      "Quarterly fundamentals (head):\n",
      "  costat curcdq datafmt indfmt consol   gvkey   datadate  fyr datacqtr  \\\n",
      "0      I    USD     STD   INDL      C  001013 1993-01-31   10   1992Q4   \n",
      "1      I    USD     STD   INDL      C  001013 1993-04-30   10   1993Q1   \n",
      "2      I    USD     STD   INDL      C  001013 1993-07-31   10   1993Q2   \n",
      "3      I    USD     STD   INDL      C  001013 1993-10-31   10   1993Q3   \n",
      "4      I    USD     STD   INDL      C  001013 1994-01-31   10   1993Q4   \n",
      "\n",
      "          rdq      atq     ceqq   cogsq    dpq     ibq     niq  ppentq  \\\n",
      "0  1993-02-22  238.483  190.883  33.526  4.984   5.260   5.260  57.347   \n",
      "1  1993-05-25  244.219  198.516  38.600  5.108   7.064   7.064  58.949   \n",
      "2  1993-08-24  255.495  208.328  39.556  5.152   9.181   9.181  61.974   \n",
      "3  1993-12-16  280.054  220.394  46.303  5.343  10.131  10.131  62.876   \n",
      "4  1994-02-22  280.447  226.487  40.412  5.619   6.695   5.245  61.606   \n",
      "\n",
      "     saleq   txtq    xrdq   xsgaq  oancfy  \n",
      "0   78.648  3.090   9.537  30.965   9.565  \n",
      "1   88.999  4.148  10.282  33.318   9.586  \n",
      "2   93.346  5.164  10.080  33.515  21.776  \n",
      "3  105.125  5.699  11.089  36.501  29.448  \n",
      "4   91.176  3.931  11.003  34.882  20.251  \n",
      "\n",
      "Yearly fundamentals (head):\n",
      "  costat curcd datafmt indfmt consol   gvkey   datadate  fyr  fyear       at  \\\n",
      "0      I   USD     STD   INDL      C  001013 1993-10-31   10   1993  280.054   \n",
      "1      I   USD     STD   INDL      C  001013 1994-10-31   10   1994  334.684   \n",
      "2      I   USD     STD   INDL      C  001013 1995-10-31   10   1995  601.083   \n",
      "3      I   USD     STD   INDL      C  001013 1996-10-31   10   1996  768.765   \n",
      "4      I   USD     STD   INDL      C  001013 1997-10-31   10   1997  936.303   \n",
      "\n",
      "       ceq    ppent     cogs      dp       ib       ni      sale     txt  \\\n",
      "0  220.394   62.876  159.461  19.111   31.636   31.636   366.118  18.101   \n",
      "1  264.758   66.132  202.925  21.658   40.521   39.071   448.735  23.800   \n",
      "2  510.866   78.686  278.886  26.341   55.186   55.186   586.222  31.043   \n",
      "3  617.470  131.080  410.288  33.794   87.463   87.463   828.009  49.200   \n",
      "4  750.795  215.677  581.981  49.843  108.837  108.837  1164.450  61.220   \n",
      "\n",
      "       xrd     xsga   oancf  \n",
      "0   40.988  134.299  29.448  \n",
      "1   48.974  159.773  58.201  \n",
      "2   66.460  196.757  44.259  \n",
      "3   90.038  250.743  63.457  \n",
      "4  122.638  344.262  79.713  \n"
     ]
    }
   ],
   "source": [
    "# LOAD COMPUSTAT (Fundamental Data)\n",
    "\n",
    "# Quarterly\n",
    "quarterly = pd.read_csv('quarterly_fundamentals.csv')\n",
    "quarterly['datadate'] = pd.to_datetime(quarterly['datadate'])\n",
    "quarterly['gvkey'] = quarterly['gvkey'].astype(str).str.zfill(6)\n",
    "print(f\"   {len(quarterly):,} quarterly observations\")\n",
    "\n",
    "# Yearly\n",
    "yearly = pd.read_csv('yearly_fundamentals.csv')\n",
    "yearly['datadate'] = pd.to_datetime(yearly['datadate'])\n",
    "yearly['gvkey'] = yearly['gvkey'].astype(str).str.zfill(6)\n",
    "print(f\"   {len(yearly):,} annual observations\")\n",
    "\n",
    "# Convert keys to strings\n",
    "quarterly['gvkey'] = quarterly['gvkey'].astype(str)\n",
    "yearly['gvkey'] = yearly['gvkey'].astype(str)\n",
    "linker['gvkey'] = linker['gvkey'].astype(str)\n",
    "linker['PERMNO'] = pd.to_numeric(linker['PERMNO'], errors='coerce')\n",
    "linker = linker.dropna(subset=['PERMNO'])\n",
    "linker['PERMNO'] = linker['PERMNO'].astype(int).astype(str).str.zfill(5)\n",
    "\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "# Print data columns\n",
    "print(\"Quarterly fundamentals (head):\")\n",
    "print(quarterly.head(5))\n",
    "print(\"\\nYearly fundamentals (head):\")\n",
    "print(yearly.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3553aa03-3ff6-4b5a-98b1-b6833055d323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quarterly fundamentals (head):\n",
      "    gvkey   datadate  fyr datacqtr         rdq      atq     ceqq   cogsq  \\\n",
      "0  001013 1993-01-31   10   1992Q4  1993-02-22  238.483  190.883  33.526   \n",
      "1  001013 1993-04-30   10   1993Q1  1993-05-25  244.219  198.516  38.600   \n",
      "2  001013 1993-07-31   10   1993Q2  1993-08-24  255.495  208.328  39.556   \n",
      "3  001013 1993-10-31   10   1993Q3  1993-12-16  280.054  220.394  46.303   \n",
      "4  001013 1994-01-31   10   1993Q4  1994-02-22  280.447  226.487  40.412   \n",
      "\n",
      "     dpq     ibq     niq  ppentq    saleq   txtq    xrdq   xsgaq  oancfy  \n",
      "0  4.984   5.260   5.260  57.347   78.648  3.090   9.537  30.965   9.565  \n",
      "1  5.108   7.064   7.064  58.949   88.999  4.148  10.282  33.318   9.586  \n",
      "2  5.152   9.181   9.181  61.974   93.346  5.164  10.080  33.515  21.776  \n",
      "3  5.343  10.131  10.131  62.876  105.125  5.699  11.089  36.501  29.448  \n",
      "4  5.619   6.695   5.245  61.606   91.176  3.931  11.003  34.882  20.251  \n",
      "\n",
      "Yearly fundamentals (head):\n",
      "    gvkey   datadate  fyr  fyear       at      ceq    ppent     cogs      dp  \\\n",
      "0  001013 1993-10-31   10   1993  280.054  220.394   62.876  159.461  19.111   \n",
      "1  001013 1994-10-31   10   1994  334.684  264.758   66.132  202.925  21.658   \n",
      "2  001013 1995-10-31   10   1995  601.083  510.866   78.686  278.886  26.341   \n",
      "3  001013 1996-10-31   10   1996  768.765  617.470  131.080  410.288  33.794   \n",
      "4  001013 1997-10-31   10   1997  936.303  750.795  215.677  581.981  49.843   \n",
      "\n",
      "        ib       ni      sale     txt      xrd     xsga   oancf  \n",
      "0   31.636   31.636   366.118  18.101   40.988  134.299  29.448  \n",
      "1   40.521   39.071   448.735  23.800   48.974  159.773  58.201  \n",
      "2   55.186   55.186   586.222  31.043   66.460  196.757  44.259  \n",
      "3   87.463   87.463   828.009  49.200   90.038  250.743  63.457  \n",
      "4  108.837  108.837  1164.450  61.220  122.638  344.262  79.713  \n"
     ]
    }
   ],
   "source": [
    "# DATA CLEANING (For Fundamentals Data)\n",
    "\n",
    "# Filter data\n",
    "quarterly = quarterly[\n",
    "    (quarterly['datafmt'] == 'STD') &\n",
    "    (quarterly['indfmt'] == 'INDL') &\n",
    "    (quarterly['consol'] == 'C') &\n",
    "    (quarterly['curcdq'] == 'USD')\n",
    "]\n",
    "yearly = yearly[\n",
    "    (yearly['datafmt'] == 'STD') &\n",
    "    (yearly['indfmt'] == 'INDL') &\n",
    "    (yearly['consol'] == 'C') &\n",
    "    (yearly['curcd'] == 'USD')\n",
    "]\n",
    "\n",
    "# Drop redundant columns\n",
    "cols_to_drop = [\n",
    "    'costat',   # company status (active/inactive)\n",
    "    'datafmt',  # format type (always 'STD' now)\n",
    "    'indfmt',   # industry format (always 'INDL')\n",
    "    'consol',   # consolidation code (always 'C')\n",
    "    'curcd', 'curcdq',  # currency codes (always 'USD')\n",
    "    'popsrc',   # population source, if present\n",
    "    'tic',      # ticker (unstable over time)\n",
    "    'cusip'     # redundant when linking via PERMNO\n",
    "]\n",
    "quarterly = quarterly.drop(columns=[c for c in cols_to_drop if c in quarterly.columns])\n",
    "yearly = yearly.drop(columns=[c for c in cols_to_drop if c in yearly.columns])\n",
    "\n",
    "# Print data columns\n",
    "print(\"Quarterly fundamentals (head):\")\n",
    "print(quarterly.head(5))\n",
    "print(\"\\nYearly fundamentals (head):\")\n",
    "print(yearly.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a712e146-76db-4ba3-ba5c-7aaabe0ef202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Quarterly: 101,665 / 109,015 observations linked (93.3%)\n",
      "   Yearly: 25,366 / 27,125 observations linked (93.5%)\n"
     ]
    }
   ],
   "source": [
    "# PERFORM LINK (Compustat -> CRSP) VIA PERMNO\n",
    "\n",
    "def add_permno(df, linker, source_name, drop_gvkey):\n",
    "    \"\"\"\n",
    "    Add PERMNO to Compustat data using time-aware linking\n",
    "    \"\"\"\n",
    "    \n",
    "    # --- Standardize dtypes ---\n",
    "    df = df.copy()\n",
    "    df['gvkey'] = df['gvkey'].astype(str).str.zfill(6)\n",
    "    linker = linker.copy()\n",
    "    linker['gvkey'] = linker['gvkey'].astype(str).str.zfill(6)\n",
    "    \n",
    "    # --- Record baseline counts ---\n",
    "    total_obs = len(df)\n",
    "    total_gvkeys = df['gvkey'].nunique()\n",
    "    \n",
    "    # --- Merge ---\n",
    "    df = df.merge(\n",
    "        linker[['gvkey', 'PERMNO', 'LINKDT', 'LINKENDDT']],\n",
    "        on='gvkey',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # --- Filter by link validity ---\n",
    "    df = df[\n",
    "        (df['datadate'] >= df['LINKDT']) &\n",
    "        (df['datadate'] <= df['LINKENDDT'])\n",
    "    ].copy()\n",
    "    \n",
    "    # --- Drop linking columns ---\n",
    "    df.drop(columns=['LINKDT', 'LINKENDDT'], inplace=True)\n",
    "    \n",
    "    # --- Drop gvkey after rekeying ---\n",
    "    if drop_gvkey:\n",
    "        df.drop(columns=['gvkey'], inplace=True, errors='ignore')\n",
    "    \n",
    "    # --- Validation summary ---\n",
    "    linked_obs = len(df)\n",
    "    linked_permnos = df['PERMNO'].notna().sum()\n",
    "    linked_gvkeys = df['PERMNO'].notna().sum()\n",
    "    \n",
    "    print(f\"   {source_name}: {linked_obs:,} / {total_obs:,} observations linked ({linked_obs / total_obs:.1%})\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Add PERMNO to fundamentals\n",
    "quarterly = add_permno(quarterly, linker, \"Quarterly\", True)\n",
    "yearly = add_permno(yearly, linker, \"Yearly\", True)\n",
    "\n",
    "# Clear memory\n",
    "del linker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8465ceb8-d2e0-4d1b-92f6-a1d0a33da4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Loaded 303,111 monthly stock observations\n",
      "   Date range: 1993-01-31 00:00:00 to 2024-12-31 00:00:00\n",
      "   Unique stocks: 1,275\n",
      "Market data (head):\n",
      "  PERMNO Ticker   MthCalDt  MthPrc      MthCap    MthRet      MthVol  ShrOut\n",
      "0  10078   SUNW 1993-01-31  39.000  4090359.00  0.159851  42128666.0  104881\n",
      "1  10078   SUNW 1993-02-28  35.125  3683945.13 -0.099359  28023855.0  104881\n",
      "2  10078   SUNW 1993-03-31  30.000  3173400.00 -0.145907  49896054.0  105780\n",
      "3  10078   SUNW 1993-04-30  27.000  2856060.00 -0.100000  39674294.0  105780\n",
      "4  10078   SUNW 1993-05-31  30.000  3173400.00  0.111111  29577640.0  105780\n"
     ]
    }
   ],
   "source": [
    "# LOAD MARKET DATA (CRSP)\n",
    "\n",
    "# Lean import\n",
    "keep_cols = [\n",
    "    'PERMNO', 'Ticker', 'MthCalDt', 'MthPrc', \n",
    "    'MthCap', 'MthRet', 'MthVol', 'ShrOut'\n",
    "]\n",
    "market_data = pd.read_csv('market_data.csv', usecols=keep_cols)\n",
    "market_data['MthCalDt'] = pd.to_datetime(market_data['MthCalDt'])\n",
    "market_data['MthCalDt'] = market_data['MthCalDt'] + MonthEnd(0)\n",
    "market_data['PERMNO'] = market_data['PERMNO'].astype(str).str.zfill(5)\n",
    "\n",
    "market_data = market_data.sort_values(['PERMNO', 'MthCalDt'])\n",
    "\n",
    "# Validation\n",
    "print(f\"   Loaded {len(market_data):,} monthly stock observations\")\n",
    "print(f\"   Date range: {market_data['MthCalDt'].min()} to {market_data['MthCalDt'].max()}\")\n",
    "print(f\"   Unique stocks: {market_data['PERMNO'].nunique():,}\")\n",
    "\n",
    "# Print data columns\n",
    "print(\"Market data (head):\")\n",
    "print(market_data.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3538e8cf-5d69-46a7-8483-76f438e39685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Constructed momentum features: mom1m, mom6m, mom12m, mom36m, chmom\n",
      "   Constructed volatility features: retvol\n",
      "   Constructed liquidity features: mvel1, dolvol, turn, std_turn\n"
     ]
    }
   ],
   "source": [
    "# CONSTRUCT MONTHLY PRICE-BASED FEATURES\n",
    "\n",
    "def construct_price_features(df):\n",
    "    \"\"\"\n",
    "    Construct key predictive features from price/return data\n",
    "    Following Gu, Kelly, and Xiu (2020)\n",
    "    \"\"\"\n",
    "    \n",
    "    features = df.copy()\n",
    "    \n",
    "    # 1. SIZE: Log market cap\n",
    "    features['mvel1'] = np.log(features['MthCap'])\n",
    "    \n",
    "    # 2. MOMENTUM FEATURES\n",
    "    # mom1m: 1-month return (t-1)\n",
    "    features['mom1m'] = features.groupby('PERMNO')['MthRet'].shift(1)\n",
    "    \n",
    "    # mom6m: 6-month momentum (t-6 to t-1, skip most recent)\n",
    "    features['mom6m'] = features.groupby('PERMNO')['MthRet'].transform(\n",
    "        lambda x: x.shift(1).rolling(6, min_periods=4).apply(lambda r: (1 + r).prod() - 1)\n",
    "    )\n",
    "    \n",
    "    # mom12m: 12-month momentum (t-12 to t-2, skip most recent)\n",
    "    features['mom12m'] = features.groupby('PERMNO')['MthRet'].transform(\n",
    "        lambda x: x.shift(2).rolling(11, min_periods=8).apply(lambda r: (1 + r).prod() - 1)\n",
    "    )\n",
    "    \n",
    "    # mom36m: 36-month momentum (long-term reversal, t-36 to t-13)\n",
    "    features['mom36m'] = features.groupby('PERMNO')['MthRet'].transform(\n",
    "        lambda x: x.shift(13).rolling(24, min_periods=18).apply(lambda r: (1 + r).prod() - 1)\n",
    "    )\n",
    "    \n",
    "    # chmom: Change in 6-month momentum\n",
    "    features['chmom'] = features.groupby('PERMNO')['mom6m'].diff(6)\n",
    "\n",
    "    print(f\"   Constructed momentum features: mom1m, mom6m, mom12m, mom36m, chmom\")\n",
    "    \n",
    "    # 3. VOLATILITY FEATURES\n",
    "    # retvol: Return volatility (12-month rolling)\n",
    "    features['retvol'] = features.groupby('PERMNO')['MthRet'].transform(\n",
    "        lambda x: x.rolling(12, min_periods=6).std()\n",
    "    )\n",
    "\n",
    "    print(f\"   Constructed volatility features: retvol\")\n",
    "    \n",
    "    # 4. LIQUIDITY FEATURES\n",
    "    # dolvol: Log dollar volume\n",
    "    dvol = features['MthVol'] * features['MthPrc']\n",
    "    dvol = dvol.where(dvol > 0, np.nan)\n",
    "    features['dolvol'] = np.log(dvol)\n",
    "    \n",
    "    # turn: Share turnover\n",
    "    features['turn'] = features['MthVol'] / features['ShrOut']\n",
    "    features['turn'] = features['turn'].replace([np.inf, -np.inf], np.nan)\n",
    "    \n",
    "    # std_turn: Volatility of turnover\n",
    "    features['std_turn'] = features.groupby('PERMNO')['turn'].transform(\n",
    "        lambda x: x.rolling(12, min_periods=6).std()\n",
    "    )\n",
    "\n",
    "    print(f\"   Constructed liquidity features: mvel1, dolvol, turn, std_turn\")\n",
    "    \n",
    "    return features\n",
    "\n",
    "market_features = construct_price_features(market_data)\n",
    "del market_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6e316a8-d6ef-41ac-81f2-9f0d6fde67b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   All chunks loaded\n",
      "   Daily data concatenated. Total daily observations: 6,327,407\n",
      "   Aggregating daily data to monthly features...\n",
      "   Aggregation complete. 302,063 stock-month observations created.\n",
      "\n",
      "   Merged daily features and updated 'baspread' and 'maxret' columns.\n",
      "\n",
      "--- Updated Market Features (Head) ---\n",
      "  PERMNO Ticker   MthCalDt  MthPrc      MthCap    MthRet      MthVol  ShrOut  \\\n",
      "0  10078   SUNW 1993-01-31  39.000  4090359.00  0.159851  42128666.0  104881   \n",
      "1  10078   SUNW 1993-02-28  35.125  3683945.13 -0.099359  28023855.0  104881   \n",
      "2  10078   SUNW 1993-03-31  30.000  3173400.00 -0.145907  49896054.0  105780   \n",
      "3  10078   SUNW 1993-04-30  27.000  2856060.00 -0.100000  39674294.0  105780   \n",
      "4  10078   SUNW 1993-05-31  30.000  3173400.00  0.111111  29577640.0  105780   \n",
      "\n",
      "       mvel1     mom1m     mom6m  mom12m  mom36m  chmom  retvol     dolvol  \\\n",
      "0  15.224143       NaN       NaN     NaN     NaN    NaN     NaN  21.219801   \n",
      "1  15.119495  0.159851       NaN     NaN     NaN    NaN     NaN  20.707480   \n",
      "2  14.970314 -0.099359       NaN     NaN     NaN    NaN     NaN  21.126650   \n",
      "3  14.864954 -0.145907       NaN     NaN     NaN    NaN     NaN  20.792051   \n",
      "4  14.970314 -0.100000 -0.197026     NaN     NaN    NaN     NaN  20.603727   \n",
      "\n",
      "         turn  std_turn  baspread    maxret  \n",
      "0  401.680629       NaN  0.005818  0.081784  \n",
      "1  267.196680       NaN  0.005723  0.036101  \n",
      "2  471.696483       NaN  0.005474  0.048673  \n",
      "3  375.064228       NaN  0.007721  0.034632  \n",
      "4  279.614672       NaN  0.007193  0.074236  \n"
     ]
    }
   ],
   "source": [
    "def process_daily_data(daily_csv_path, chunk_size=1_000_000):\n",
    "    \"\"\"\n",
    "    Processes a large daily data CSV in chunks to calculate\n",
    "    monthly aggregates for bid-ask spread and max daily return.\n",
    "\n",
    "    This function correctly handles chunk boundaries by delaying\n",
    "    aggregation until all data is loaded.\n",
    "\n",
    "    Args:\n",
    "        daily_csv_path (str): The path to the 'daily.csv' file.\n",
    "        chunk_size (int): The number of rows to read per chunk.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with PERMNO, MthCalDt,\n",
    "                      baspread (monthly avg), and maxret (monthly max).\n",
    "    \"\"\"\n",
    "    \n",
    "    daily_chunks = []\n",
    "\n",
    "    dtype_map = {\n",
    "        'PERMNO': 'Int64',\n",
    "        'DlyCalDt': 'string',\n",
    "        'DlyAsk': 'float64',\n",
    "        'DlyBid': 'float64',\n",
    "        'DlyRet': 'float64'\n",
    "    }\n",
    "    \n",
    "    # We must iterate with an index to get the first chunk for column validation\n",
    "    for i, chunk in enumerate(pd.read_csv(\n",
    "        daily_csv_path, \n",
    "        chunksize=chunk_size, \n",
    "        dtype=dtype_map,\n",
    "        low_memory=False)):\n",
    "        \n",
    "        if i == 0:\n",
    "            # Validate required columns (PERMNO is essential)\n",
    "            required_cols = ['PERMNO', 'DlyCalDt', 'DlyAsk', 'DlyBid', 'DlyRet']\n",
    "            if not all(col in chunk.columns for col in required_cols):\n",
    "                print(f\"   Error: missing {required_cols}\")\n",
    "                print(f\"   Found: {list(chunk.columns)}\")\n",
    "                return pd.DataFrame()\n",
    "        \n",
    "        # --- 1. Process Daily Data (Inside Chunk) ---\n",
    "        \n",
    "        # Convert date\n",
    "        chunk['DlyCalDt'] = pd.to_datetime(chunk['DlyCalDt'], errors='coerce')\n",
    "        \n",
    "        # Calculate daily spread\n",
    "        chunk['daily_spread'] = np.where(\n",
    "            (chunk['DlyAsk'] + chunk['DlyBid']) > 0,\n",
    "            (chunk['DlyAsk'] - chunk['DlyBid']) / ((chunk['DlyAsk'] + chunk['DlyBid']) / 2),\n",
    "            np.nan\n",
    "        )\n",
    "        chunk = chunk[['PERMNO', 'DlyCalDt', 'DlyRet', 'daily_spread']]\n",
    "        \n",
    "        daily_chunks.append(chunk)\n",
    "\n",
    "    print(f\"   All chunks loaded\")\n",
    "    \n",
    "    # --- 2. Aggregate (After Concatenation) ---\n",
    "    \n",
    "    daily_df = pd.concat(daily_chunks, ignore_index=True)\n",
    "    daily_df = daily_df.dropna(subset=['PERMNO', 'DlyCalDt'])\n",
    "    \n",
    "    print(f\"   Daily data concatenated. Total daily observations: {len(daily_df):,}\")\n",
    "    \n",
    "    # Create the monthly grouping key\n",
    "    daily_df['year_month'] = daily_df['DlyCalDt'].dt.to_period('M')\n",
    "    \n",
    "    print(\"   Aggregating daily data to monthly features...\")\n",
    "    \n",
    "    # Now, perform a single, correct aggregation\n",
    "    monthly_agg = daily_df.groupby(['PERMNO', 'year_month']).agg(\n",
    "        # Calculate mean bid-ask spread for the month\n",
    "        baspread=('daily_spread', 'mean'), \n",
    "        \n",
    "        # Find the maximum daily return for the month\n",
    "        maxret=('DlyRet', 'max') # This is the new, accurate maxret\n",
    "    ).reset_index()\n",
    "\n",
    "    print(f\"   Aggregation complete. {len(monthly_agg):,} stock-month observations created.\")\n",
    "    \n",
    "    # --- 3. Final Formatting ---\n",
    "    \n",
    "    # Convert 'year_month' to a month-end timestamp\n",
    "    monthly_agg['MthCalDt'] = monthly_agg['year_month'].dt.to_timestamp('M') + pd.offsets.MonthEnd(0)\n",
    "    \n",
    "    # Drop the temporary key\n",
    "    monthly_agg = monthly_agg.drop(columns='year_month')\n",
    "    \n",
    "    return monthly_agg\n",
    "\n",
    "daily_features_df = process_daily_data('daily.csv')\n",
    "daily_features_df['PERMNO'] = daily_features_df['PERMNO'].astype(str)\n",
    "daily_features_df['MthCalDt'] = pd.to_datetime(daily_features_df['MthCalDt'])\n",
    "\n",
    "# Merge the daily-based features\n",
    "market_features = market_features.merge(\n",
    "    daily_features_df,\n",
    "    on=['PERMNO', 'MthCalDt'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "del daily_features_df\n",
    "\n",
    "print(\"\\n   Merged daily features and updated 'baspread' and 'maxret' columns.\")\n",
    "print(\"\\n--- Updated Market Features (Head) ---\")\n",
    "print(market_features.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "740628f7-424c-4c52-8567-6f96b7964015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Constructed yearly features: be, agr, op, operprof, ep_numerator, rd_numerator\n",
      "   Constructed quarterly feature: earnings_ttm\n"
     ]
    }
   ],
   "source": [
    "# CONSTRUCT FUNDAMENTALS-BASED FEATURES\n",
    "\n",
    "def construct_fundamental_features(quarterly, yearly):\n",
    "    \"\"\"\n",
    "    Construct fundamental features from Compustat data.\n",
    "    This version correctly implements GKX features.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. YEARLY FEATURES\n",
    "    yearly = yearly.sort_values(['PERMNO', 'datadate'])\n",
    "    \n",
    "    # 'be': Book Equity (uses 'ceq' - Common Equity)\n",
    "    # This is a point-in-time value for the fiscal year-end.\n",
    "    yearly['be'] = yearly['ceq']\n",
    "    yearly = yearly.drop('ceq', axis=1)\n",
    "\n",
    "    # 'agr': Asset Growth (year-over-year % change in 'at' - Total Assets)\n",
    "    # This is (at[t] - at[t-1]) / at[t-1], known at time t.\n",
    "    yearly['agr'] = yearly.groupby('PERMNO')['at'].pct_change(fill_method=None)\n",
    "    \n",
    "    # 1. Calculate Operating Profit\n",
    "    # (FillNa(0) assumes missing cogs/xsga are 0, which is standard)\n",
    "    yearly['op'] = yearly['sale'].fillna(0) - yearly['cogs'].fillna(0) - yearly['xsga'].fillna(0)\n",
    "    \n",
    "    # 2. Calculate Ratio (using np.where to avoid divide-by-zero)\n",
    "    yearly['operprof'] = np.where(\n",
    "        yearly['be'] > 0,  # Only calculate if Book Equity is positive\n",
    "        yearly['op'] / yearly['be'],\n",
    "        np.nan\n",
    "    )\n",
    "    \n",
    "    # 'ep_numerator': Earnings (Numerator for E/P ratio)\n",
    "    # Uses 'ib' (Income Before Extraordinary Items - Yearly)\n",
    "    yearly['ep_numerator'] = yearly['ib']\n",
    "    \n",
    "    # 'rd_numerator': R&D (Numerator for R&D/MVE ratio)\n",
    "    # Uses 'xrd' (R&D Expense). Fill missing with 0.\n",
    "    yearly['rd_numerator'] = yearly['xrd'].fillna(0)\n",
    "\n",
    "    print(\"   Constructed yearly features: be, agr, op, operprof, ep_numerator, rd_numerator\")\n",
    "    \n",
    "    # 2. QUARTERLY FEATURES\n",
    "    quarterly = quarterly.sort_values(['PERMNO', 'rdq'])\n",
    "    \n",
    "    # 'earnings_ttm': Trailing 12-Month Earnings\n",
    "    # Sum of the last 4 quarters of 'ibq' (Income - Quarterly)\n",
    "    quarterly['earnings_ttm'] = quarterly.groupby('PERMNO')['ibq'].transform(\n",
    "        lambda x: x.rolling(4, min_periods=4).sum()\n",
    "    )\n",
    "    \n",
    "    print(\"   Constructed quarterly feature: earnings_ttm\")\n",
    "    \n",
    "    return yearly, quarterly\n",
    "\n",
    "yearly_features, quarterly_features = construct_fundamental_features(\n",
    "    quarterly, yearly\n",
    ")\n",
    "\n",
    "del quarterly\n",
    "del yearly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4712e36a-4965-4555-a7d3-4932bc85d2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Prepared 24,991 fundamental records with reporting lag\n",
      "   Completed point-in-time matching for 1,275 stocks\n",
      "   Final dataset: 303,111 stock-month observations\n"
     ]
    }
   ],
   "source": [
    "## CREATE POINT-IN-TIME FUNDAMENTALS\n",
    "\n",
    "def create_point_in_time_fundamentals(market_df, fundamental_df):\n",
    "    \"\"\"\n",
    "    Create point-in-time fundamental features for each stock-month.\n",
    "    Handles reporting lag to avoid look-ahead bias.\n",
    "    \n",
    "    Args:\n",
    "        market_df: Monthly market data with PERMNO and MthCalDt\n",
    "        fundamental_df: Fundamental data with PERMNO already linked\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with point-in-time fundamental features merged\n",
    "    \"\"\"\n",
    "    \n",
    "    # Prepare fundamental data with reporting lag\n",
    "    fund = fundamental_df.copy()\n",
    "    \n",
    "    # Add 4-month reporting lag to avoid look-ahead bias\n",
    "    # Fundamentals reported on datadate are available 4 months later\n",
    "    fund['available_date'] = fund['datadate'] + pd.DateOffset(months=4)\n",
    "    \n",
    "    # Select columns needed for matching\n",
    "    fund_columns = ['PERMNO', 'available_date', 'be', 'agr', 'operprof', \n",
    "                    'at', 'ep_numerator', 'rd_numerator']\n",
    "    fund = fund[fund_columns].copy()\n",
    "    \n",
    "    # Remove any rows with missing critical data\n",
    "    fund = fund.dropna(subset=['PERMNO', 'available_date'])\n",
    "    \n",
    "    # Remove duplicates - keep most recent if multiple records on same available_date\n",
    "    fund = fund.sort_values(['PERMNO', 'available_date', 'be'])\n",
    "    fund = fund.drop_duplicates(subset=['PERMNO', 'available_date'], keep='last')\n",
    "    \n",
    "    print(f\"   Prepared {len(fund):,} fundamental records with reporting lag\")\n",
    "    \n",
    "    # Sort both dataframes for merge_asof\n",
    "    market = market_df.sort_values(['PERMNO', 'MthCalDt']).reset_index(drop=True)\n",
    "    fund = fund.sort_values(['PERMNO', 'available_date']).reset_index(drop=True)\n",
    "    \n",
    "    # Perform point-in-time merge using merge_asof by PERMNO\n",
    "    merged_list = []\n",
    "    \n",
    "    for permno in market['PERMNO'].unique():\n",
    "        # Get data for this stock\n",
    "        market_stock = market[market['PERMNO'] == permno].copy()\n",
    "        fund_stock = fund[fund['PERMNO'] == permno].copy()\n",
    "        \n",
    "        if len(fund_stock) == 0:\n",
    "            # No fundamental data for this stock - keep market data as-is\n",
    "            merged_list.append(market_stock)\n",
    "            continue\n",
    "        \n",
    "        # Point-in-time merge: for each MthCalDt, use most recent available fundamental\n",
    "        # direction='backward' means we look back for the latest available data\n",
    "        merged = pd.merge_asof(\n",
    "            market_stock,\n",
    "            fund_stock.drop(columns=['PERMNO']),  # Drop PERMNO since it's in left df\n",
    "            left_on='MthCalDt',\n",
    "            right_on='available_date',\n",
    "            direction='backward',\n",
    "            allow_exact_matches=True\n",
    "        )\n",
    "        \n",
    "        merged_list.append(merged)\n",
    "    \n",
    "    # Combine all stocks\n",
    "    result = pd.concat(merged_list, ignore_index=True)\n",
    "    \n",
    "    print(f\"   Completed point-in-time matching for {result['PERMNO'].nunique():,} stocks\")\n",
    "    \n",
    "    # Compustat fundamentals are in millions, CRSP MthCap is in thousands\n",
    "    result['MthCap_millions'] = result['MthCap'] / 1000\n",
    "    \n",
    "    # Calculate ratio features using merged data\n",
    "    # Book-to-market ratio\n",
    "    result['bm'] = result['be'] / result['MthCap_millions']\n",
    "    result['bm'] = result['bm'].replace([np.inf, -np.inf], np.nan)\n",
    "    \n",
    "    # Earnings-to-price ratio (if ep_numerator exists)\n",
    "    if 'ep_numerator' in result.columns:\n",
    "        result['ep'] = result['ep_numerator'] / result['MthCap_millions']\n",
    "        result['ep'] = result['ep'].replace([np.inf, -np.inf], np.nan)\n",
    "    \n",
    "    # R&D-to-market-cap ratio (if rd_numerator exists)\n",
    "    if 'rd_numerator' in result.columns:\n",
    "        result['rd_mve'] = result['rd_numerator'] / result['MthCap_millions']\n",
    "        result['rd_mve'] = result['rd_mve'].replace([np.inf, -np.inf], np.nan)\n",
    "    \n",
    "    # Drop intermediate columns\n",
    "    result = result.drop(columns=['available_date', 'MthCap_millions'], errors='ignore')\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Apply point-in-time matching to yearly fundamentals\n",
    "all_features = create_point_in_time_fundamentals(market_features, yearly_features)\n",
    "print(f\"   Final dataset: {len(all_features):,} stock-month observations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6397e20a-c4ea-4b06-b54a-bfedf2e9c349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- All Features (Head) ---\n",
      "  PERMNO Ticker   MthCalDt    MthRet      mvel1     mom1m     mom6m  mom12m  \\\n",
      "0  10078   SUNW 1993-01-31  0.159851  15.224143       NaN       NaN     NaN   \n",
      "1  10078   SUNW 1993-02-28 -0.099359  15.119495  0.159851       NaN     NaN   \n",
      "2  10078   SUNW 1993-03-31 -0.145907  14.970314 -0.099359       NaN     NaN   \n",
      "3  10078   SUNW 1993-04-30 -0.100000  14.864954 -0.145907       NaN     NaN   \n",
      "4  10078   SUNW 1993-05-31  0.111111  14.970314 -0.100000 -0.197026     NaN   \n",
      "\n",
      "   chmom  retvol     dolvol        turn  std_turn  baspread    maxret  agr  \\\n",
      "0    NaN     NaN  21.219801  401.680629       NaN  0.005818  0.081784  NaN   \n",
      "1    NaN     NaN  20.707480  267.196680       NaN  0.005723  0.036101  NaN   \n",
      "2    NaN     NaN  21.126650  471.696483       NaN  0.005474  0.048673  NaN   \n",
      "3    NaN     NaN  20.792051  375.064228       NaN  0.007721  0.034632  NaN   \n",
      "4    NaN     NaN  20.603727  279.614672       NaN  0.007193  0.074236  NaN   \n",
      "\n",
      "   operprof  bm  ep  rd_mve  \n",
      "0       NaN NaN NaN     NaN  \n",
      "1       NaN NaN NaN     NaN  \n",
      "2       NaN NaN NaN     NaN  \n",
      "3       NaN NaN NaN     NaN  \n",
      "4       NaN NaN NaN     NaN  \n"
     ]
    }
   ],
   "source": [
    "# Clean up dataframes no longer needed\n",
    "'''\n",
    "del quarterly_features\n",
    "del yearly_features\n",
    "del market_features\n",
    "'''\n",
    "\n",
    "# Remove unnecessary columns\n",
    "columns_to_drop = ['MthPrc', 'MthCap', 'MthVol', 'ShrOut', 'be', 'at', 'ep_numerator', 'rd_numerator', 'mom36m']\n",
    "all_features = all_features.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "print(\"\\n--- All Features (Head) ---\")\n",
    "print(all_features.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbb16b88-35da-4b7e-a500-9c79db8f9b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Loaded 1,308 membership records\n",
      "   Unique PERMNOs: 1,275\n",
      "   Added S&P 500 membership indicator\n",
      "   Non-S&P 500 stock-months: 109,976\n",
      "   S&P 500 coverage: 63.7% of stock-months\n"
     ]
    }
   ],
   "source": [
    "# CREATE S&P 500 MEMBERSHIP INDICATOR\n",
    "\n",
    "# LOAD S&P 500 MEMBERSHIP DATA\n",
    "membership = pd.read_csv('membership.csv')\n",
    "membership['start'] = pd.to_datetime(membership['start'])\n",
    "membership['ending'] = pd.to_datetime(membership['ending'])\n",
    "membership = membership.rename(columns={'permno': 'PERMNO'})\n",
    "membership['PERMNO'] = pd.to_numeric(membership['PERMNO'], errors='coerce')\n",
    "membership = membership.dropna(subset=['PERMNO'])\n",
    "membership['PERMNO'] = membership['PERMNO'].astype(int).astype(str).str.zfill(5)\n",
    "\n",
    "print(f\"   Loaded {len(membership):,} membership records\")\n",
    "print(f\"   Unique PERMNOs: {membership['PERMNO'].nunique():,}\")\n",
    "\n",
    "# Create the indicator\n",
    "def create_sp500_indicator(market_df, membership_df):\n",
    "    \"\"\"\n",
    "    Create point-in-time indicator for S&P 500 membership.\n",
    "    Expands membership periods into monthly indicators to avoid look-ahead bias.\n",
    "    \n",
    "    Args:\n",
    "        market_df: Market data with PERMNO and MthCalDt\n",
    "        membership_df: S&P membership with PERMNO, start, ending dates\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with in_sp500 binary indicator added\n",
    "    \"\"\"\n",
    "    \n",
    "    membership_expanded = []\n",
    "    \n",
    "    for idx, row in membership_df.iterrows():\n",
    "        # Create date range for this membership period (month-end dates)\n",
    "        dates = pd.date_range(row['start'], row['ending'], freq='ME')\n",
    "        \n",
    "        for date in dates:\n",
    "            membership_expanded.append({\n",
    "                'PERMNO': row['PERMNO'],\n",
    "                'MthCalDt': date,\n",
    "                'in_sp500': 1\n",
    "            })\n",
    "    \n",
    "    sp500_indicator = pd.DataFrame(membership_expanded)\n",
    "    \n",
    "    # Merge with market data (left join preserves all market observations)\n",
    "    result = market_df.merge(\n",
    "        sp500_indicator,\n",
    "        on=['PERMNO', 'MthCalDt'],\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Fill missing with 0 (not in S&P 500)\n",
    "    result['in_sp500'] = result['in_sp500'].fillna(0).astype(int)\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Apply S&P 500 indicator to all_features\n",
    "all_features = create_sp500_indicator(all_features, membership)\n",
    "\n",
    "print(f\"   Added S&P 500 membership indicator\")\n",
    "print(f\"   Non-S&P 500 stock-months: {(all_features['in_sp500']==0).sum():,}\")\n",
    "print(f\"   S&P 500 coverage: {all_features['in_sp500'].mean()*100:.1f}% of stock-months\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba40bc65-4533-4392-8e34-e888e9ba2bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "DATA VALIDATION\n",
      "================================================================================\n",
      "\n",
      "1. DATE ALIGNMENT\n",
      "----------------------------------------\n",
      "Month-end day distribution:\n",
      "MthCalDt\n",
      "31    176815\n",
      "30    101000\n",
      "28     19042\n",
      "29      6254\n",
      "Name: count, dtype: int64\n",
      "✓ All dates are proper month-ends\n",
      "\n",
      "2. PERMNO FORMAT\n",
      "----------------------------------------\n",
      "Sample PERMNOs: ['10078', '10078', '10078']\n",
      "✓ All PERMNOs are 5-digit zero-padded strings\n",
      "\n",
      "3. FEATURE AVAILABILITY (Post Feb-2024)\n",
      "----------------------------------------\n",
      "Mature data: 7,287 observations from 2024-02-29 00:00:00\n",
      "   ✓  1. mom1m           -  99.9% available\n",
      "   ✓  2. mom6m           -  99.8% available\n",
      "   ✓  3. mom12m          -  99.4% available\n",
      "   ❌  4. mom36m          - MISSING\n",
      "   ✓  5. chmom           -  99.4% available\n",
      "   ✓  6. mvel1           - 100.0% available\n",
      "   ✓  7. dolvol          - 100.0% available\n",
      "   ✓  8. turn            - 100.0% available\n",
      "   ✓  9. std_turn        -  99.7% available\n",
      "   ✓ 10. retvol          -  99.7% available\n",
      "   ✓ 11. maxret          - 100.0% available\n",
      "   ✓ 12. baspread        - 100.0% available\n",
      "   ✓ 13. bm              -  99.5% available\n",
      "   ✓ 14. agr             -  98.6% available\n",
      "   ✓ 15. operprof        -  93.1% available\n",
      "\n",
      "4. S&P 500 MEMBERSHIP\n",
      "----------------------------------------\n",
      "Unique S&P 500 stocks by year:\n",
      "MthCalDt\n",
      "1993    512\n",
      "1994    516\n",
      "1995    527\n",
      "1996    521\n",
      "1997    524\n",
      "1998    536\n",
      "1999    539\n",
      "2000    550\n",
      "2001    527\n",
      "2002    521\n",
      "2003    509\n",
      "2004    519\n",
      "2005    516\n",
      "2006    530\n",
      "2007    535\n",
      "2008    533\n",
      "2009    524\n",
      "2010    515\n",
      "2011    518\n",
      "2012    517\n",
      "2013    518\n",
      "2014    515\n",
      "2015    528\n",
      "2016    530\n",
      "2017    531\n",
      "2018    528\n",
      "2019    525\n",
      "2020    521\n",
      "2021    522\n",
      "2022    521\n",
      "2023    517\n",
      "2024    520\n",
      "Name: PERMNO, dtype: int64\n",
      "\n",
      "Overall S&P coverage: 63.7% of stock-months\n",
      "\n",
      "5. FUNDAMENTAL COVERAGE BY YEAR\n",
      "----------------------------------------\n",
      "             bm    agr  operprof\n",
      "MthCalDt                        \n",
      "1993        803     17       803\n",
      "1994       8210    900      8103\n",
      "1995      10148   8080      9987\n",
      "1996      10326   9979     10115\n",
      "1997      10469  10114     10297\n",
      "1998      10459  10141     10263\n",
      "1999      10321  10030     10100\n",
      "2000      10125   9857      9919\n",
      "2001       9917   9691      9701\n",
      "2002       9960   9685      9712\n",
      "2003       9895   9756      9601\n",
      "2004       9870   9817      9635\n",
      "2005       9904   9763      9665\n",
      "2006       9769   9610      9534\n",
      "2007       9550   9426      9309\n",
      "2008       9400   9251      9236\n",
      "2009       9214   9145      8893\n",
      "2010       9100   9080      8771\n",
      "2011       9054   8957      8757\n",
      "2012       9051   8952      8739\n",
      "2013       9058   8946      8757\n",
      "2014       9074   8953      8772\n",
      "2015       9013   8914      8725\n",
      "2016       8825   8716      8468\n",
      "2017       8647   8555      8274\n",
      "2018       8560   8468      8142\n",
      "2019       8396   8313      7976\n",
      "2020       8285   8192      7855\n",
      "2021       8177   8104      7758\n",
      "2022       8042   7999      7569\n",
      "2023       7921   7879      7401\n",
      "2024       7902   7839      7395\n",
      "\n",
      "6. OUTLIER DETECTION\n",
      "----------------------------------------\n",
      "\n",
      "bm:\n",
      "count    7247.000000\n",
      "mean        0.400385\n",
      "std         0.727509\n",
      "min       -18.115026\n",
      "1%         -0.260234\n",
      "5%         -0.019316\n",
      "50%         0.293524\n",
      "95%         1.220810\n",
      "99%         2.441569\n",
      "max        19.285208\n",
      "Name: bm, dtype: float64\n",
      "\n",
      "mom12m:\n",
      "count    7245.000000\n",
      "mean        0.195930\n",
      "std         0.380851\n",
      "min        -0.895387\n",
      "1%         -0.484268\n",
      "5%         -0.272761\n",
      "50%         0.158446\n",
      "95%         0.751434\n",
      "99%         1.319604\n",
      "max         8.580101\n",
      "Name: mom12m, dtype: float64\n",
      "\n",
      "retvol:\n",
      "count    7266.000000\n",
      "mean        0.089339\n",
      "std         0.053981\n",
      "min         0.024509\n",
      "1%          0.034248\n",
      "5%          0.042874\n",
      "50%         0.079962\n",
      "95%         0.158431\n",
      "99%         0.257939\n",
      "max         1.333796\n",
      "Name: retvol, dtype: float64\n",
      "\n",
      "agr:\n",
      "count    7187.000000\n",
      "mean        0.049421\n",
      "std         0.211917\n",
      "min        -0.566351\n",
      "1%         -0.287416\n",
      "5%         -0.122475\n",
      "50%         0.031525\n",
      "95%         0.252617\n",
      "99%         0.547537\n",
      "max         7.502193\n",
      "Name: agr, dtype: float64\n",
      "\n",
      "7. POINT-IN-TIME VALIDATION\n",
      "----------------------------------------\n",
      "   PERMNO 10078: Market starts 1993-01, Fundamentals start 1993-10 (lag: 9 months)\n",
      "   PERMNO 10104: Market starts 1993-01, Fundamentals start 1993-09 (lag: 8 months)\n",
      "   PERMNO 10107: Market starts 1993-01, Fundamentals start 1993-10 (lag: 9 months)\n",
      "   PERMNO 10108: Market starts 1993-01, Fundamentals start 1994-04 (lag: 15 months)\n",
      "   PERMNO 10137: Market starts 1993-01, Fundamentals start 1994-04 (lag: 15 months)\n",
      "\n",
      "================================================================================\n",
      "SUMMARY\n",
      "================================================================================\n",
      "✓ Total observations: 303,111\n",
      "✓ Date range: 1993-01 to 2024-12\n",
      "✓ Unique stocks: 1,275\n",
      "✓ Mature data (post Feb-2024): 7,287 observations\n",
      "✓ Features constructed: 15\n"
     ]
    }
   ],
   "source": [
    "# DATA VALIDATION\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DATA VALIDATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Define feature set\n",
    "feature_list = [\n",
    "    # Momentum features\n",
    "    'mom1m', 'mom6m', 'mom12m', 'mom36m', 'chmom',\n",
    "    # Size & liquidity\n",
    "    'mvel1', 'dolvol', 'turn', 'std_turn',\n",
    "    # Volatility\n",
    "    'retvol', 'maxret',\n",
    "    # Spread\n",
    "    'baspread',\n",
    "    # Fundamentals\n",
    "    'bm', 'agr', 'operprof',\n",
    "]\n",
    "\n",
    "# 1. CHECK DATE ALIGNMENT\n",
    "print(\"\\n1. DATE ALIGNMENT\")\n",
    "print(\"-\" * 40)\n",
    "print(\"Month-end day distribution:\")\n",
    "print(all_features['MthCalDt'].dt.day.value_counts().head())\n",
    "assert all_features['MthCalDt'].dt.is_month_end.all(), \"❌ Not all dates are month-end!\"\n",
    "print(\"✓ All dates are proper month-ends\")\n",
    "\n",
    "# 2. CHECK PERMNO FORMAT\n",
    "print(\"\\n2. PERMNO FORMAT\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Sample PERMNOs: {all_features['PERMNO'].head(3).tolist()}\")\n",
    "assert all_features['PERMNO'].str.len().eq(5).all(), \"❌ PERMNOs not all 5 digits!\"\n",
    "print(\"✓ All PERMNOs are 5-digit zero-padded strings\")\n",
    "\n",
    "# 3. FEATURE AVAILABILITY (after Feb 2024 when all lags populated)\n",
    "print(\"\\n3. FEATURE AVAILABILITY (Post Feb-2024)\")\n",
    "print(\"-\" * 40)\n",
    "mature_data = all_features[all_features['MthCalDt'] >= '2024-02-29']\n",
    "print(f\"Mature data: {len(mature_data):,} observations from {mature_data['MthCalDt'].min()}\")\n",
    "\n",
    "for i, feat in enumerate(feature_list, 1):\n",
    "    if feat in mature_data.columns:\n",
    "        pct_available = (mature_data[feat].notna().sum() / len(mature_data) * 100)\n",
    "        status = \"✓\" if pct_available > 80 else \"⚠️\"\n",
    "        print(f\"   {status} {i:2d}. {feat:15s} - {pct_available:5.1f}% available\")\n",
    "    else:\n",
    "        print(f\"   ❌ {i:2d}. {feat:15s} - MISSING\")\n",
    "\n",
    "# 4. S&P 500 MEMBERSHIP CHECK\n",
    "print(\"\\n4. S&P 500 MEMBERSHIP\")\n",
    "print(\"-\" * 40)\n",
    "yearly_sp = all_features[all_features['in_sp500']==1].groupby(\n",
    "    all_features['MthCalDt'].dt.year\n",
    ")['PERMNO'].nunique()\n",
    "print(\"Unique S&P 500 stocks by year:\")\n",
    "print(yearly_sp)\n",
    "print(f\"\\nOverall S&P coverage: {all_features['in_sp500'].mean()*100:.1f}% of stock-months\")\n",
    "if yearly_sp.median() < 450 or yearly_sp.median() > 550:\n",
    "    print(\"⚠️  Warning: S&P 500 count seems unusual (expected ~500)\")\n",
    "\n",
    "# 5. FUNDAMENTAL COVERAGE BY YEAR\n",
    "print(\"\\n5. FUNDAMENTAL COVERAGE BY YEAR\")\n",
    "print(\"-\" * 40)\n",
    "yearly_fund = all_features.groupby(\n",
    "    all_features['MthCalDt'].dt.year\n",
    ")[['bm', 'agr', 'operprof']].count()\n",
    "print(yearly_fund)\n",
    "\n",
    "# 6. OUTLIER DETECTION\n",
    "print(\"\\n6. OUTLIER DETECTION\")\n",
    "print(\"-\" * 40)\n",
    "for feat in ['bm', 'mom12m', 'retvol', 'agr']:\n",
    "    if feat in mature_data.columns:\n",
    "        print(f\"\\n{feat}:\")\n",
    "        print(mature_data[feat].describe(percentiles=[.01, .05, .95, .99]))\n",
    "\n",
    "# 7. POINT-IN-TIME CHECK (fundamentals should lag market data)\n",
    "print(\"\\n7. POINT-IN-TIME VALIDATION\")\n",
    "print(\"-\" * 40)\n",
    "# Check that we don't have fundamentals available too early\n",
    "# Sample a few stocks and verify fundamental dates respect the 4-month lag\n",
    "sample_permnos = all_features['PERMNO'].unique()[:5]\n",
    "for permno in sample_permnos:\n",
    "    stock_data = all_features[all_features['PERMNO'] == permno].copy()\n",
    "    # First non-null fundamental should be at least 4 months after data start\n",
    "    first_market = stock_data['MthCalDt'].min()\n",
    "    first_fundamental = stock_data[stock_data['bm'].notna()]['MthCalDt'].min()\n",
    "    if pd.notna(first_fundamental):\n",
    "        lag_months = (first_fundamental.year - first_market.year) * 12 + (first_fundamental.month - first_market.month)\n",
    "        print(f\"   PERMNO {permno}: Market starts {first_market.strftime('%Y-%m')}, \"\n",
    "              f\"Fundamentals start {first_fundamental.strftime('%Y-%m')} (lag: {lag_months} months)\")\n",
    "\n",
    "# 8. FINAL SUMMARY\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"✓ Total observations: {len(all_features):,}\")\n",
    "print(f\"✓ Date range: {all_features['MthCalDt'].min().strftime('%Y-%m')} to {all_features['MthCalDt'].max().strftime('%Y-%m')}\")\n",
    "print(f\"✓ Unique stocks: {all_features['PERMNO'].nunique():,}\")\n",
    "print(f\"✓ Mature data (post Feb-2024): {len(mature_data):,} observations\")\n",
    "print(f\"✓ Features constructed: {len(feature_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d79d6e9-a1aa-470d-8fe8-a80ee5781515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating target variable...\n",
      "   Target variable created: 301,280 observations\n",
      "   Final dataset: 301,280 rows\n"
     ]
    }
   ],
   "source": [
    "# ADD TARGET VARIABLE (next month's return)\n",
    "print(\"\\nCreating target variable...\")\n",
    "all_features = all_features.sort_values(['PERMNO', 'MthCalDt'])\n",
    "all_features['target_ret'] = all_features.groupby('PERMNO')['MthRet'].shift(-1)\n",
    "\n",
    "# Remove last observation for each stock (no target available)\n",
    "all_features = all_features.dropna(subset=['target_ret'])\n",
    "\n",
    "print(f\"   Target variable created: {all_features['target_ret'].notna().sum():,} observations\")\n",
    "print(f\"   Final dataset: {len(all_features):,} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42d04b29-244e-4124-9918-4b15d5a947b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: data.csv\n",
      "Size: 301,280 observations\n",
      "Stocks: 1,275\n",
      "\n",
      "Column list: ['PERMNO', 'Ticker', 'MthCalDt', 'MthRet', 'mvel1', 'mom1m', 'mom6m', 'mom12m', 'chmom', 'retvol', 'dolvol', 'turn', 'std_turn', 'baspread', 'maxret', 'agr', 'operprof', 'bm', 'ep', 'rd_mve', 'in_sp500', 'target_ret']\n"
     ]
    }
   ],
   "source": [
    "output_file = 'data.csv'\n",
    "all_features.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"File: {output_file}\")\n",
    "print(f\"Size: {len(all_features):,} observations\")\n",
    "print(f\"Stocks: {all_features['PERMNO'].nunique():,}\")\n",
    "print(f\"\\nColumn list: {list(all_features.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9d677d-9f3d-4f9c-88b0-835d2d7dcb9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
